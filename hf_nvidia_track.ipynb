{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NVIDIA Product Texts — Exhaustive NLP Testing (Hugging Face Transformers)\n",
        "\n",
        "\"\"\"\n",
        "This notebook provides a modern 2025-ready NLP workflow for analyzing **NVIDIA product descriptions** using the **Hugging Face Transformers** library.\n",
        "\n",
        "It performs comprehensive NLP tasks including text classification, summarization, NER, and embeddings similarity using pre-trained transformer models.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "wNqn2LfkDBW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Setup ===\n",
        "# Install dependencies\n",
        "!pip install -q transformers datasets torch sentencepiece accelerate\n",
        "!pip install -q beautifulsoup4 requests numpy"
      ],
      "metadata": {
        "id": "IQezkPflC_Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b2c010e"
      },
      "source": [
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cec58a93"
      },
      "source": [
        "# === Fetch NVIDIA Product Data ===\n",
        "def fetch_nvidia_products():\n",
        "    try:\n",
        "        url = \"https://www.nvidia.com/en-us/data-center/products/\"\n",
        "        soup = BeautifulSoup(requests.get(url).text, 'html.parser')\n",
        "        products = [a.text.strip() for a in soup.find_all('a') if 'NVIDIA' in a.text]\n",
        "        return list(set([p for p in products if len(p) < 100]))[:20]\n",
        "    except:\n",
        "        return [\n",
        "            \"NVIDIA GeForce RTX 4090\",\n",
        "            \"NVIDIA A100 Tensor Core GPU\",\n",
        "            \"NVIDIA DGX H100 system\",\n",
        "            \"NVIDIA HGX platform\",\n",
        "            \"NVIDIA Blackwell architecture\",\n",
        "            \"NVIDIA RTX 5090 Ti upcoming GPU\",\n",
        "        ]\n",
        "\n",
        "nvidia_products = fetch_nvidia_products()\n",
        "print(\"Sample products:\", nvidia_products[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6e52820"
      },
      "source": [
        "# === Pipelines Setup ===\n",
        "\n",
        "# 1. Named Entity Recognition\n",
        "ner_pipe = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
        "\n",
        "# 2. Summarization\n",
        "sum_pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# 3. Zero-shot classification (categorize products)\n",
        "zero_shot = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# 4. Embedding model for similarity\n",
        "embed_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "tok = AutoTokenizer.from_pretrained(embed_model_name)\n",
        "embed_model = AutoModel.from_pretrained(embed_model_name)\n",
        "\n",
        "def get_embedding(text):\n",
        "    inputs = tok(text, return_tensors='pt', truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = embed_model(**inputs)\n",
        "    emb = outputs.last_hidden_state.mean(dim=1)\n",
        "    return emb / emb.norm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb9c16b9"
      },
      "source": [
        "# === Exhaustive Testing ===\n",
        "\n",
        "for text in nvidia_products:\n",
        "    print(f\"\\n=== {text} ===\")\n",
        "    print(\"NER:\", ner_pipe(text))\n",
        "    # Dynamically set max_length for summarization, ensuring it's at least min_length\n",
        "    summary_max_length = max(min(len(text.split()), 20), 5) # set max length to the maximum of (number of words in the text or 20) and 5\n",
        "    print(\"Summary:\", sum_pipe(text, max_length=summary_max_length, min_length=5, do_sample=False)[0]['summary_text'])\n",
        "    print(\"Category:\", zero_shot(text, candidate_labels=[\"GPU\", \"Server\", \"Chip\", \"AI System\", \"Platform\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7da762e"
      },
      "source": [
        "# === Similarity Testing ===\n",
        "\n",
        "def cosine(a, b):\n",
        "    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))\n",
        "\n",
        "embs = [get_embedding(t).numpy().flatten() for t in nvidia_products]\n",
        "print(\"\\nPairwise product similarities:\")\n",
        "for i in range(len(nvidia_products)):\n",
        "    for j in range(i + 1, len(nvidia_products)):\n",
        "        sim = cosine(embs[i], embs[j])\n",
        "        if sim > 0.7:\n",
        "            print(f\"{nvidia_products[i]} ↔ {nvidia_products[j]} = {sim:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72b27ec0"
      },
      "source": [
        "\"\"\"\n",
        "README — Hugging Face Transformers NVIDIA NLP Test\n",
        "\n",
        "This notebook demonstrates a comprehensive NLP evaluation using Hugging Face pipelines:\n",
        "\n",
        "### Tasks Covered\n",
        "- **NER**: Extracts entities (models, architectures, hardware terms)\n",
        "- **Summarization**: Generates concise summaries of NVIDIA product names or descriptions\n",
        "- **Zero-shot Classification**: Assigns each product to categories like GPU, AI System, or Platform\n",
        "- **Embedding Similarity**: Measures semantic closeness among product names\n",
        "\n",
        "### Models Used\n",
        "- `dslim/bert-base-NER` — general-purpose named entity recognition\n",
        "- `facebook/bart-large-cnn` — summarization\n",
        "- `facebook/bart-large-mnli` — zero-shot classification\n",
        "- `sentence-transformers/all-MiniLM-L6-v2` — sentence embeddings for similarity\n",
        "\n",
        "### How to Run\n",
        "1. Install dependencies via pip commands in the setup cell.\n",
        "2. Run all cells sequentially in a Jupyter or Colab environment.\n",
        "3. Review outputs printed for each NVIDIA product name.\n",
        "4. Modify `candidate_labels` or extend with your own data for custom evaluations.\n",
        "\n",
        "### Extension Ideas\n",
        "- Replace `MiniLM` with `bge-large` or `text-embedding-3-large` for higher embedding accuracy.\n",
        "- Use `faiss` or `qdrant` for scalable vector similarity search.\n",
        "- Add question-answering (`pipeline('question-answering')`) for product feature extraction.\n",
        "- Integrate results into a FastAPI or Streamlit dashboard.\n",
        "\"\"\""
      ]
    }
  ]
}